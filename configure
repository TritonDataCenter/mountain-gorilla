#!/bin/bash
# vi: tabstop=4 expandtab shiftwidth=4
#
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
#

#
# Copyright (c) 2018, Joyent, Inc.
#

#
# Configure the mountain gorilla (aka SDC) build.
#
# "targets.json" is a mapping of Makefile target to info about that target.
# It is generated from targets.json.in.

if [ "$TRACE" != "" ]; then
    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
    set -o xtrace
fi
set -o errexit
set -o pipefail

#---- config, globals

BRANCH=master
TRY_BRANCH=
MG_DEP_USER=
MG_DEP_PATH=
JOYENT_DEP_PATH=
MG_OUT_PATH=

ROOT=$(pwd)
MG_CACHE_DIR=${ROOT}/cache

MGET_BIT_ARGS="-q"
if [[ -n ${MGET_PROGRESS} ]]; then
    MGET_BIT_ARGS="--progress"
fi
MANTA_MAX_RETRIES=3

export PATH="${ROOT}/node_modules/manta/bin:${PATH}"

if [[ $(uname -s) == "SunOS" ]]; then
    MTIME='stat -c %Z'
else
    MTIME='stat -f %m'
fi

# GNU cp has '--link'.
if [[ -x `which gcp` ]]; then
    CP_LINK="gcp --link"
else
    CP_LINK=$( (cp --version 2>/dev/null | grep GNU >/dev/null) && echo "cp --link" || echo "cp" )
fi
CURL="curl --fail --connect-timeout 10 -s"

#
# Git has not always supported the "--recursive" option to "git submodule sync".
#
GIT_SUBMODULE_SYNC_FLAGS=''
if git submodule -h | grep 'git submodule .* sync .*--recursive' \
    >/dev/null; then

    GIT_SUBMODULE_SYNC_FLAGS='--recursive'
fi


#---- internal support functions

function fatal {
    echo "$(basename $0): error: $1"
    exit 1
}

function errexit {
    [[ $1 -ne 0 ]] || exit 0
    fatal "error exit status $1 at line $2"
}

function ensure_manta_credentials {
    if [[ -z "$MANTA_KEY_ID" ]]; then
        export MANTA_KEY_ID=`ssh-keygen -l -f ~/.ssh/id_rsa.pub | awk '{print $2}' | tr -d '\n'`
    fi
    export MANTA_URL=https://us-east.manta.joyent.com
    if [[ -z "$MANTA_USER" ]]; then
        export MANTA_USER="Joyent_Dev";
    fi

    #
    # manta_base_path is used for preloading bits. So if we've been
    # passed in a -d option, we should use that here.
    #
    if [[ -z "$MG_DEP_USER" ]]; then
        MG_DEP_USER="$MANTA_USER"
    fi
    export manta_base_path="/$MG_DEP_USER${MG_DEP_PATH}"
}

# Blow away the bits cache once per-day because don't want it to grow
# unbounded in size (esp. for the continuous-build system). An alternative
# would be to put a size limit on it.
function flush_bits_cache() {
    if [[ -f $MG_CACHE_DIR/bits/created ]]; then
        local bits_cache_age=$((`date "+%s"` - `$MTIME $MG_CACHE_DIR/bits/created`))
        # One day in 86400. We use a bit more to avoid harmonics with
        # once-per-day builds.
        if [[ $bits_cache_age -gt 100000 ]]; then
            echo "# Bit cache '$MG_CACHE_DIR/bits' is more than a day old. Blowing it away to be recreated."
            rm -rf $MG_CACHE_DIR/bits
        fi
    fi
}

# areload $MG_CACHE_DIR/bits/ with the latest built and uploaded bits for
# the given target and branch via HTTP(S).
#
# Usage:
#   preload_bits_from_http TARGET BRANCH TRY_BRANCH
# where:
#   TARGET is a URL dir that serves Apache/Nginx-index-style directories.
#
# Example:
#   preload_bits_from_http http://download.joyent.com/pub/build/sdcnode master ""
#
function preload_bits_from_http() {
    local target=$1
    local branch=$2
    local try_branch=$3
    local target_base=$(basename $target)

    if [[ "$target_base" == "sdcnode" ]]; then
        echo "Skip preload of sdcnode (see RELENG-404)."
        return
    fi

    echo ""
    echo "# preload 'bits/$target_base'"

    local target_url
    [[ $(echo $target | cut -c 1-4) == "http" ]] || fatal "preload_bits_from_http called w/o http URL"

    target_url=$target
    if [[ "${target_url:(-1)}" != "/" ]]; then
        target_url=$target_url/
    fi
    local_cache_reldir=${target_url#*://}
    local_cache_reldir=${local_cache_reldir#*@}

    # Branch dir: try $try_branch, then $branch.
    local best_branch=$try_branch
    local latest_url=$target_url$try_branch-latest/
    if [[ -z "$best_branch" ||
          $($CURL -kI $latest_url | head -1 | awk '{print $2}') != "200" ]]; then
        best_branch=$branch
        latest_url=$target_url$branch-latest/
        if [[ $($CURL -kIS $latest_url | head -1 | awk '{print $2}') != "200" ]]; then
            fatal "'$target_url/$branch-latest/' does not exist"
        fi
    fi
    echo "# use branch '$best_branch'"

    # Find the latest build time for this branch.
    local latest_build=$($CURL -Sk $target_url \
        | grep "href=\"" \
        | cut -d'"' -f2 \
        | grep "^$best_branch-" \
        | grep -v -- '-latest/$' \
        | sort \
        | tail -1)
    local local_cache_dir=$MG_CACHE_DIR/bits/$local_cache_reldir$latest_build$target_base

    if [[ -d $local_cache_dir ]]; then
        echo "# local cache at '$local_cache_dir' already exists"
    else
        # Mark creation for bits cache flush every day.
        mkdir -p $MG_CACHE_DIR/bits
        if [[ ! -f $MG_CACHE_DIR/bits/created ]]; then
            touch $MG_CACHE_DIR/bits/created
        fi

        latest_url=$target_url$latest_build

        # Update cache in $MG_CACHE_DIR/bits
        # `-l 2`: Two levels deep needed for 2-level depth of 'agents' bits area.
        echo "# download from $latest_url"
        (cd $MG_CACHE_DIR/bits \
            && wget -q -np -l 2 --no-check-certificate -r -L -R 'index.html,*.log' \
                $latest_url$target_base/)
    fi
    local md5sums_path=$local_cache_dir/../md5sums.txt
    if [[ ! -f $md5sums_path ]]; then
        $CURL -Sk ${latest_url}md5sums.txt -o $md5sums_path
    fi

    # MD5 check of downloaded bits.
    for bit in $(cd $local_cache_dir/../ && find . -type f | grep -v md5sums.txt); do
        local correct_md5=$(grep $bit $md5sums_path | cut -d ' ' -f1)
        local actual_md5=$(openssl dgst -md5 < $local_cache_dir/../$bit | awk '{print $NF}')
        if [[ $correct_md5 != $actual_md5 ]]; then
            rm $local_cache_dir/../$bit
            fatal "md5 check failure on $local_cache_dir/../$bit (actual '$actual_md5', from md5sums '$correct_md5')"
        fi
    done

    # Copy over to bits dir.
    mkdir -p bits
    [[ -d "bits/$target_base" ]] && fatal "'bits/$target_base' already exists"
    $CP_LINK -PR $local_cache_dir bits/$target_base
}

#
# Preload $MG_CACHE_DIR/bits/ with the latest built and uploaded bits for
# the given target and branch.
#
# Usage:
#   preload_bits_from_manta TARGET BRANCH TRY_BRANCH
#
# Example:
#   preload_bits_from_manta smartlogin master ""
#   preload_bits_from_manta release-20110901-upgrade/agents-upgrade master ""
#
function preload_bits_from_manta() {
    local target=$1
    local branch=$2
    local try_branch=$3
    local target_base=$(basename $target)
    local start_time=$(date +%s)

    # Don't bork if this was already preloaded by another target.
    if [[ -d bits/$target_base ]]; then
        return;
    fi

    # If bit is in the LOCAL_BITS_CACHE, use that
    if [[ -n ${LOCAL_BITS_DIR} && -d ${LOCAL_BITS_DIR}/${target_base} ]]; then
        mkdir -p bits
        cp -PR ${LOCAL_BITS_DIR}/${target_base} bits/${target_base}
        return;
    fi

    # This is a hack here for the case where we've got something like:
    #
    # https://download.joyent.com/pub/build/sdcnode
    #
    # in the 'deps'. We'll then use HTTP to download that bit.
    if [[ $(echo $target | cut -c 1-4) == "http" ]]; then
        preload_bits_from_http $@
        return 0
    fi

    echo ""
    echo "# preload 'bits/$target_base from Manta'"

    ensure_manta_credentials

    # You can specify "target" as branch/target, in which case we will use
    # the branch from there. If target does not have '/', dirname returns '.'
    local target_branch=$(dirname $target)
    if [[ "$target_branch" != "." ]]; then
        branch=$target_branch
    fi

    # Remember: target_base is something like 'agents-upgrade'
    local target_mpath=${manta_base_path}/${target_base}

    # Allow to set JOYENT_DEP_PATH=/stor/builds for joyent bits
    if [[ ${target_base} == "firmware-tools" && -n ${JOYENT_DEP_PATH} ]]; then
        target_mpath="/${MG_DEP_USER}${JOYENT_DEP_PATH}/${target_base}"
    fi

    # Branch dir: try $try_branch, then $branch.
    local best_branch=$try_branch
    if [[ -z $best_branch ]]; then
        best_branch=$branch
    fi

    local builds_subdir="public"
    local consider_prev_releases=0
    local delay=0
    local dirnames=
    #
    # Each build dir has a "${branch}-latest" file, e.g.
    # "/Joyent_Dev/stor/builds/amon/master-latest" that contains the name
    # of the actual latest path. Something similar but with a "-<buildstamp>"
    # instead of "-latest" and we'll grab that into latest_dir.
    #
    local latest_dir=
    local previous_releases=
    local success=

    if [[ $(cat ${ROOT}/targets.json | $JSON ${target_base}.public) == 'false' \
        ]]; then
        builds_subdir="stor"
    fi

    dirnames[${#dirnames[@]}]="${best_branch}-latest"
    if [[ "$branch" != "$best_branch" ]]; then
        dirnames[${#dirnames[@]}]="${branch}-latest"
    fi

    consider_prev_releases=$(echo ,"${CONSIDER_PREV_RELEASES_FOR}", | \
        grep ",$target_base,") || true
    if [[ "$consider_prev_releases" != "" ]]; then
        dirnames[${#dirnames[@]}]=$(mls /Joyent_Dev/${builds_subdir}/builds/${target_base} | \
            grep -E 'release-[[:digit:]]{8}-latest' | sort | tail -1)
    fi;

    set +o errexit  # want to do our own error-handling here
    for dir_name in ${dirnames[@]}; do
        local count=0
        while [[ ${count} -lt ${MANTA_MAX_RETRIES} && -z ${success} ]]; do

            if [[ ${count} -gt 0 ]]; then
                cat /tmp/mget-output.$$
                delay=$((${count} * 20))
                if [[ $delay -gt 60 ]]; then
                    delay=60
                fi
                echo "Could not get latest dir for target ${target}, retrying in ${delay}s"
                sleep ${delay}
            fi

            latest_dir=$(mget -v -q ${target_mpath}/${dir_name} 2> /tmp/mget-output.$$)

            if [[ $? == 0 ]]; then
                success=1
                break;
            fi

            count=$((${count} + 1))
        done

        if [[ $success -eq 1 ]]; then
            break;
        fi
    done
    set -o errexit  # back to errexit

    if [[ -z ${latest_dir} ]]; then
        cat /tmp/mget-output.$$
        fatal "Could not get latest dir for target $target"
    fi

    # local_cache_dir will be something like:
    # /root/MG/cache/bits/agents-upgrade/master-20131213T003614Z
    local local_cache_dir=${MG_CACHE_DIR}/bits/${latest_dir#$manta_base_path/}
    mkdir -p ${local_cache_dir}

    # Mark creation for bits cache flush every day.
    if [[ ! -f $MG_CACHE_DIR/bits/created ]]; then
        touch $MG_CACHE_DIR/bits/created
    fi

    local cache_dirname=
    local cache_filename=
    local dir=
    local files=$(mfind -v -t o ${latest_dir})
    local found=
    local local_file_md5=
    local manta_file_md5=
    local retries=

    if [[ -z ${files} ]]; then
        fatal "failed to get files from ${latest_dir}"
    fi

    # loop through all the objects in the latest_dir
    for file in $files; do
        dir=$(dirname $file)
        cache_dirname=$(echo "${local_cache_dir}/${dir#${latest_dir}}" | sed -e "s/\/$//g" | sed -e "s|//|/|g")
        cache_filename=$(basename ${file})
        manta_file_md5=$(mmd5 -v ${file} | cut -d' ' -f1)

        # Ensure directory exists
        mkdir -p ${cache_dirname}

        retries=0
        while [[ ${retries} -lt ${MANTA_MAX_RETRIES} ]]; do
            if [[ ! -f ${cache_dirname}/${cache_filename} ]]; then
                mget -v ${MGET_BIT_ARGS} -o ${cache_dirname}/${cache_filename} ${file}
            fi

            local_file_md5=$(openssl dgst -md5 ${cache_dirname}/${cache_filename} | awk '{print $NF}')
            if [[ ${local_file_md5} == ${manta_file_md5} ]]; then
                echo "# ${cache_dirname}/${cache_filename} has correct MD5"
                break;
            else
                echo "# ${cache_dirname}/${cache_filename} has incorrect MD5, deleting"
                rm -f ${cache_dirname}/${cache_filename}
            fi
            retries=$((${retries} + 1))
        done

        [[ -f ${cache_dirname}/${cache_filename} ]] \
            || fatal "failed to preload ${cache_dirname}/${cache_filename}"
    done

    # Copy over to bits dir.
    mkdir -p bits
    [[ -d "bits/${target_base}" ]] && fatal "'bits/${target_base}' already exists"
    $CP_LINK -PR ${local_cache_dir}/${target_base} bits/${target_base}

    local end_time=$(date +%s)
    echo "$((${end_time} - ${start_time})) seconds to preload ${target_base}"
}

# Clone/update the given git repo in the repo cache.
# Usage:
#   get_repo_cache REPO-URL REPO-DIR [GERRIT-CR]
# Example:
#   get_repo_cache git@github.com:joyent/smart-login.git \
#     $MG_CACHE_DIR/repos/smart-login 4095/2
function get_repo_cache() {
    local repo_url=$1
    local cache_dir=$2
    local gerrit_cr=$3

    if [[ ! -d "$cache_dir" ]]; then
        local parent_dir=$(dirname $cache_dir)
        local tmp_dir=$parent_dir/.tmp.$repo_dir
        mkdir -p $parent_dir
        rm -rf $tmp_dir
        git clone $repo_url $tmp_dir
        mv $tmp_dir $cache_dir
    else
        (cd $cache_dir; git pull)
    fi

    if [[ -n "$gerrit_cr" ]]; then
        (cd $cache_dir && git fetch origin \
        +refs/heads/*:refs/remotes/origin/* +refs/changes/*:refs/remotes/origin/changes/*)
    fi

    # Error out if the cached repo is dirty. These things should always
    # be pristine.
    if [[ "$(cd $cache_dir && git describe --all --dirty | grep dirty)" != "" ]]; then
        fatal "Repo cache $cache_dir is dirty!"
    fi
}


# Get the requested repo.
# Usage:
#   get_repo2 REPO-URL BRANCH SUBMODULE-UPDATE [NAME] [TRY-BRANCH] [GERRIT-CR]
#
# If "SUBMODULE-UPDATE" is "true", then "git submodule update ..." is
# used on the repo.
#
# If "NAME" is given, that subdir under "build/" will be used as the
# clone dir. Else it is inferred from the REPO-URL.
#
# Only one of TRY-BRANCH or GERRIT_CR should be set.
#
function get_repo2() {
    local repo_url=$1
    local branch=$2
    local submodule_update=$3
    local repo_dir=$4
    local try_branch=$5
    local gerrit_cr=$6

    if [[ -z "$repo_dir" ]]; then
        repo_dir=${repo_url##*/}    # strip to last '/'
        repo_dir=${repo_dir##*:}    # strip to last ':'
        repo_dir=${repo_dir%*.git}    # strip '.git' at tail
    fi

    local cache_dir=$MG_CACHE_DIR/repos/$repo_dir
    if [[ -n "$gerrit_cr" ]]; then
        cache_dir=$MG_CACHE_DIR/repos.cr/$repo_dir
    fi

    echo "# get '$repo_url' to repo cache dir '$cache_dir'"
    get_repo_cache ${repo_url} ${cache_dir} ${gerrit_cr}

    echo "# copy '$cache_dir' to 'build/$repo_dir'"
    mkdir -p build
    cp -PR $cache_dir build/$repo_dir
    (cd build/$repo_dir ; git checkout $branch)

    if [[ -n "$try_branch" ]]; then
        (cd build/$repo_dir ; git checkout $try_branch && git pull || true)
    fi

    if [[ -n "$gerrit_cr" ]]; then
        # 4920/2 -> remotes/origin/changes/20/4920/2
        ref=$(echo $gerrit_cr | \
            sed 's+\(.*\)\(..\)/+remotes/origin/changes/\2/\1\2/+')
        (cd build/$repo_dir ; git checkout $ref || true)
    fi

    if [[ "$submodule_update" == "true" ]]; then
        (cd "build/$repo_dir" &&
            git submodule sync $GIT_SUBMODULE_SYNC_FLAGS &&
            git submodule update --init --recursive)
    fi
}

function gen_config() {
    local output
    mkdir -p bits
    local bra_name
    # Determine UPDATES_CHANNEL based into branch name:
    if [[ ! -z "$TRY_BRANCH" ]]; then
        bra_name=${TRY_BRANCH}
    else
        bra_name=${BRANCH}
    fi
    if [[ -z "$TRY_BRANCH" && "$(echo ${BRANCH} | grep '^release-[0-9]\{8\}$' || true)" ]]; then
        UPDATES_CHANNEL=staging
    else
        if [[ "${bra_name}" == "master" ]]; then
            UPDATES_CHANNEL=dev
        else
            UPDATES_CHANNEL=experimental
        fi
    fi
    cat <<EOF >bits/config.mk
TIMESTAMP=$(TZ=UTC date "+%Y%m%dT%H%M%SZ")
BRANCH=$BRANCH
TRY_BRANCH=$TRY_BRANCH
MG_GERRIT_CR=$MG_GERRIT_CR
MG_NODE=$MG_NODE
MG_CACHE_DIR=$(cd $MG_CACHE_DIR >/dev/null; pwd)
JOYENT_BUILD=$JOYENT_BUILD
MG_OUT_PATH=${MG_OUT_PATH}
UPDATES_CHANNEL=${UPDATES_CHANNEL}
EOF
  mkdir -p build
  for repo in $(ls -1 build/); do
      repo_mk_name=$(echo $repo | tr [:lower:] [:upper:] | tr - _)
      branch_name=$((cd build/${repo} && git symbolic-ref HEAD 2> /dev/null ) || echo "")
      echo ${repo_mk_name}_BRANCH=$(echo ${branch_name##refs/heads/} || echo "") >> ${ROOT}/bits/config.mk
      echo ${repo_mk_name}_SHA=$((cd build/${repo} && git log --pretty=format:'%h' -1 ) || echo "") >> ${ROOT}/bits/config.mk
  done

  # Makefile vars for appliance builds (i.e. the "foo_image" targets).
  for targ in $TARGETS; do
      targ_mk_name=$(echo $targ | tr [:lower:] [:upper:] | tr - _)
      if [[ $(cat ${ROOT}/targets.json | $JSON ${targ} | $JSON appliance) == 'true' ]]; then
        echo ${targ_mk_name}_IMAGE_UUID=$(cat ${ROOT}/targets.json | $JSON ${targ}.image_uuid) >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_IMAGE_NAME=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.image_name)\" >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_IMAGE_DESCRIPTION=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.image_description)\" >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_PKGSRC=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.pkgsrc | $JSON -a |  xargs)\" >> ${ROOT}/bits/config.mk
        local num_tarballs=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.length)
        local tarballs=""
        local index=0
        while [[ ${index} -lt ${num_tarballs} ]]; do
            local tb_name=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.name)
            local tb_tarball=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.tarball)
            [[ -z "$tb_tarball" ]] && fatal "no '$targ.tarballs.$index.tarball' in targets.json"
            tb_tarball=$ROOT/bits/$tb_tarball
            local tb_sysroot=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.sysroot)
            [[ -z "$tb_sysroot" ]] && fatal "no '$targ.tarballs.$index.sysroot' in targets.json"
            tarballs="$tarballs $tb_tarball:$tb_sysroot"
            index=$((${index} + 1))
        done
        echo ${targ_mk_name}_EXTRA_TARBALLS=\"${tarballs}\" >> ${ROOT}/bits/config.mk
      fi
  done
}


function print_help() {
    echo "Configure this SDC build. This involves cloning/pulling the "
    echo "component source repositories."
    echo ""
    echo "Usage:"
    echo "  ./configure [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -B TRY-BRANCH"
    echo "               Branch to try to checkout (if it exists). '-b' value"
    echo "               is used as the default. This is useful for building"
    echo "               a feature branch on one of the many repos used for"
    echo "               a target."
    echo "  -D PATH      Alternate Manta path for dependencies. The default is"
    echo "               '/stor/builds'."
    echo "  -J PATH      Alternate manta path for joyent-only dependencies. The"
    echo "               default is to use the -D path."
    echo "  -O PATH      Alternate Manta path for 'make <target>_upload_manta'."
    echo "               The default is '\${MANTA_USER}/stor/builds'."
    echo "  -P           Ignore the 'build_platform' check that is meant to ensure"
    echo "               that a component is built on the exact platform version"
    echo "               specified for it in 'targets.json' for release."
    echo "  -R [COMPONENT_NAME1,COMPONENT_NAME2,...]"
    echo "               Consider using previous releases if latest release is not"
    echo "               available."
    echo "  -b BRANCH    Branch to checkout. Defaults to 'master'."
    echo "               Note that this is for *all* core repositories."
    echo "  -c CACHE-DIR Specify a cache directory. Default: './cache'."
    echo "               The cache is used for caching git clones, preloaded"
    echo "               bits and npm downloads. The 'bits cache' is"
    echo "               automatically removed if it is more than a day old."
    echo "  -d USER      Alternate Manta user to pull dependencies from. eg. if"
    echo "               building as yourself, -d Joyent_Dev will pull deps "
    echo "               from normal builds."
    echo "  -g [gerrit]  build using the given Gerrit CR changeset"
    echo "  -h, --help   Print this help and exit."
    echo "  -j           Configure this workspace to build Joyent products."
    echo "  -r           Regenerate config.mk. This doesn't touch repos in"
    echo "               'build/' or preload in 'bits/'."
    echo "  -t TARGET    Prepare to build only this target. Valid targets are"
    echo "               the keys of 'targets.json'."
    exit 0
}


function get_target_repos() {
    local target=$1
    local info
    for info in `cat targets.json | $JSON $target.repos | $JSON -a -d, url dir submodule-update`; do
        local repo_url=$(echo "$info" | cut -d, -f 1)
        local repo_dir=$(echo "$info" | cut -d, -f 2)
        local submodule_update=$(echo "$info" | cut -d, -f 3)
        [[ -z "$submodule_update" ]] && submodule_update=true
        get_repo2 $repo_url $BRANCH "$submodule_update" \
            "$repo_dir" "$TRY_BRANCH" "$MG_GERRIT_CR"
    done
}

# Ensure that we are building on the specified build_platform in targets.json.
function ensure_build_platform() {
    local target=$1
    local build_platform
    local errmsg
    build_platform=$(cat targets.json | $JSON $target.build_platform)
    if [[ -n "$build_platform" ]]; then
        curr_platform=$(uname -v | cut -d_ -f2)
        if [[ "$curr_platform" != "$build_platform" ]]; then
            errmsg="current platform, $curr_platform, does not match the expected '$target.build_platform', $build_platform"
            if [[ $IGNORE_BUILD_PLATFORM_CHECK == "yes" ]]; then
                echo "warning: $errmsg (ignoring, per '-P' option)"
            else
                fatal "$errmsg"
            fi
        fi
    fi
}

function get_pkgsrc() {
  if [[ -d ${ROOT}/build/usb-headnode ]]; then
    echo "# get pkgsrc packages for build/usb-headnode zones (to build/pkgsrc)"

    mkdir -p build/pkgsrc/

    shopt -s extglob

    for dataset in $(find ${ROOT}/build/usb-headnode/zones -name "dataset"); do
      local ds=$(cat ${dataset})
      local pkgsrc_url=$((${JSON} datasets | ${JSON} -a name pkgsrc_url \
          | grep "$(basename ${ds%\.dsmanifest})" \
          | cut -d ' ' -f2) < ${ROOT}/build/usb-headnode/build.spec)
      if [[ ${pkgsrc_url:(-1)} != "/" ]]; then
        pkgsrc_url=$pkgsrc_url/
      fi
      local pkgsrc_ver=$(echo "${pkgsrc_url}" | cut -d '/' -f5)
      local gccver=$(echo "${pkgsrc_url}" | cut -d '/' -f6)

      local cache_dir=$MG_CACHE_DIR/pkgsrc/$pkgsrc_ver/$gccver/All
      local dest_dir=build/pkgsrc/${pkgsrc_ver}/${gccver}/All
      mkdir -p $cache_dir
      mkdir -p $dest_dir

      if [[ ! -f $dest_dir/../SHA512.bz2 ]]; then
        echo "# get ${pkgsrc_url}/../SHA512.bz2"
        if ${CURL} -S -o $cache_dir/../SHA512.bz2 ${pkgsrc_url}/../SHA512.bz2; then
          $CP_LINK $cache_dir/../SHA512.bz2 $dest_dir/../SHA512.bz2
        elif [[ ! -f $dest_dir/md5sums.txt ]]; then
          echo "# get ${pkgsrc_url}md5sums.txt"
          ${CURL} -S -o $cache_dir/md5sums.txt ${pkgsrc_url}md5sums.txt
          $CP_LINK $cache_dir/md5sums.txt $dest_dir/md5sums.txt
        fi
      fi

      for file in $(cat $(dirname ${dataset})/pkgsrc); do
        if [[ -f $dest_dir/$file.tgz ]]; then
          true # pass through
        else
          if [[ ! -f $cache_dir/${file}.tgz ]]; then
            echo "# get ${pkgsrc_url}${file}.tgz"
            ${CURL} -S -o $cache_dir/$file.tgz ${pkgsrc_url}/${file}.tgz

            if [[ -f $cache_dir/../SHA512.bz2 ]]; then
              local correct_sha512=$(bzcat ${cache_dir}/../SHA512.bz2 | grep "/${file}.tgz)" | cut -d' ' -f4)
              local actual_sha512=$(openssl dgst -sha512 < $cache_dir/$file.tgz | awk '{print $NF}')
              if [[ $correct_sha512 != $actual_sha512 ]]; then
                rm $cache_dir/$file.tgz
                fatal "SHA512 check failure on $cache_dir/$file.tgz (actual $actual_sha512, from SHA512.bz2 $correct_sha512)"
              fi
            elif [[ -f $cache_dir/md5sums.txt ]]; then
              local correct_md5=$(grep $file $cache_dir/md5sums.txt | cut -d ' ' -f1)
              local actual_md5=$(openssl dgst -md5 < $cache_dir/$file.tgz | awk '{print $NF}')
              if [[ $correct_md5 != $actual_md5 ]]; then
                rm $cache_dir/$file.tgz
                fatal "md5 check failure on $cache_dir/$file.tgz (actual $actual_md5, from md5sums $correct_md5)"
              fi
            fi
          else
            echo "# have $cache_dir/$file.tgz"
          fi
          $CP_LINK $cache_dir/$file.tgz $dest_dir/
        fi
      done
    done

  fi
}




#---- mainline

# Can be a target name to tell 'configure' to (a) limit prep to just that
# target and (b) pre-load "bits/" with pre-built dependent target bits.
# If empty it means that we are configuring for a full build.
TARGET=
REGENERATE='false'
MG_NODE=$(which node) || fatal "node binary not found on PATH"
IGNORE_BUILD_PLATFORM_CHECK=no

trap 'errexit $? $LINENO' EXIT

if [[ "$1" == "--help" ]]; then
  print_help
fi
while getopts "B:D:J:O:PR:b:c:d:g:hjrt:" opt; do
    case "$opt" in
        B) TRY_BRANCH=$OPTARG ;;
        D) MG_DEP_PATH=${OPTARG} ;;
        J) JOYENT_DEP_PATH=${OPTARG} ;;
        O) MG_OUT_PATH=${OPTARG} ;;
        P) IGNORE_BUILD_PLATFORM_CHECK=yes ;;
        R) CONSIDER_PREV_RELEASES_FOR=${OPTARG} ;;
        b) BRANCH=$OPTARG ;;
        c) MG_CACHE_DIR=${OPTARG} ;;
        d) MG_DEP_USER=${OPTARG} ;;
        g) MG_GERRIT_CR=${OPTARG} ;;
        h) print_help ;;
        j) JOYENT_BUILD=true ;;
        r) REGENERATE='true' ;;
        t) TARGET=${OPTARG} ;;
        ?) fatal "unknown option: $opt" ;;
    esac
done
shift $((OPTIND-1))

[[ -n "$MG_GERRIT_CR" ]] && {
    [[ -n "$TRY_BRANCH" ]] && {
        echo "Can't use -g with -B" >&2
        exit 1
    }

    export MG_GERRIT_CR
    export MG_GIT_PREFIX=http://cr.joyent.us/joyent
}

[[ -z ${MG_DEP_PATH} ]] && MG_DEP_PATH=/public/builds
[[ -z $JOYENT_BUILD ]] && JOYENT_BUILD=false
export JOYENT_BUILD
rm -f targets.json
bash < targets.json.in | json > targets.json

# Pre-condition: must have node >=0.10 first on path (see RELENG-266).
echo "Ensure have a 'node' >= v0.10."
NODE_MAJOR_VERSION=$($MG_NODE --version | cut -c2- | awk 'BEGIN{ FS="." } { print $1 }')
NODE_MINOR_VERSION=$($MG_NODE --version | awk 'BEGIN{ FS="." } { print $2 }')
if [[ $NODE_MAJOR_VERSION -lt 1 && $NODE_MINOR_VERSION -lt 10 ]]; then
    fatal "Incorrect node version, '${NODE_MAJOR_VERSION}.${NODE_MINOR_VERSION}'. MG needs a node v0.10 or later on your PATH."
fi
JSON="$MG_NODE $ROOT/tools/json"

# make sure we clean out old versions before installing the new one
for nodething in manta smartdc; do
    if [[ -f node_modules/${nodething}/package.json
         && $(json version < node_modules/${nodething}/package.json) \
         != $(json dependencies.${nodething} < package.json) ]]; then

        rm -rf node_modules/${nodething}
    fi
done

# Make sure npm stuff is installed
npm install

# '-r' regenerate early out.
if [[ "$REGENERATE" == 'true' ]]; then
    gen_config
    exit 0
fi


# Else we are doing a full configure for a fresh build. Start fresh:
mkdir -p bits
touch bits/config.mk
make distclean

if [[ ! -z "$TARGET" ]]; then
    flush_bits_cache
    # Validate target.
    TARGETS=$TARGET
    if [[ -z "$(cat targets.json | $JSON $TARGET)" ]]; then
        fatal "Unknown target: $TARGET"
    fi
    ensure_build_platform $TARGET
    get_target_repos $TARGET
    for dep in `cat targets.json | $JSON $TARGET.deps | $JSON -a`; do
        if [[ -n "$(echo $dep | egrep '^[^/]+/[^/]+$' || true)" ]]; then
            # Using the 'BRANCH/NAME' form to lock to a branch.
            dep_branch=$(echo $dep | cut -d/ -f1)
            dep=$(echo $dep | cut -d/ -f2)
            preload_bits_from_manta ${dep} "${dep_branch}"
        else
            preload_bits_from_manta ${dep} "$BRANCH" "$TRY_BRANCH"
        fi
    done
else
    TARGETS=$(${MG_NODE} -e 'fs=require("fs"); c=fs.readFileSync("targets.json"); console.log(Object.keys(JSON.parse(c)).join("\n"))')
    for targ in $TARGETS; do
        ensure_build_platform $targ
        get_target_repos $targ
    done
fi

# "all" is a special target with deps to always preload.
# I.e. for which "make all" doesn't build it.
#for dep in `cat targets.json | $JSON all.deps | $JSON -a`; do
    #if [[ -n "$(echo $dep | egrep '^[^/]+/[^/]+$' || true)" ]]; then
        ## Using the 'BRANCH/NAME' form to lock to a branch.
        #dep_branch=$(echo $dep | cut -d/ -f1)
        #dep=$(echo $dep | cut -d/ -f2)
        #preload_bits_from_manta ${dep} "${dep_branch}"
    #else
        #preload_bits_from_manta ${dep} "$BRANCH" "$TRY_BRANCH"
    #fi
#done

#get_pkgsrc

gen_config

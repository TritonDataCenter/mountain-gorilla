#!/bin/bash
# vi: tabstop=4 expandtab shiftwidth=4
#
# Configure the mountain gorilla (aka SDC) build.
#
# "targets.json" is a mapping of Makefile target to info about that target.

if [ "$TRACE" != "" ]; then
    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
    set -o xtrace
fi
set -o errexit
set -o pipefail

#---- config, globals

BRANCH=master
TRY_BRANCH=
MG_DEP_USER=

ROOT=$(pwd)
MG_CACHE_DIR=${ROOT}/cache

MGET_BIT_ARGS="-q"
if [[ -n ${MGET_PROGRESS} ]]; then
    MGET_BIT_ARGS="--progress"
fi
MANTA_MAX_RETRIES=3

export PATH="${ROOT}/node_modules/manta/bin:${PATH}"

if [[ $(uname -s) == "SunOS" ]]; then
    MTIME='stat -c %Z'
else
    MTIME='stat -f %m'
fi

# GNU cp has '--link'.
if [[ -x `which gcp` ]]; then
    CP_LINK="gcp --link"
else
    CP_LINK=$( (cp --version 2>/dev/null | grep GNU >/dev/null) && echo "cp --link" || echo "cp" )
fi
CURL="curl --fail --connect-timeout 10 -s"


#---- internal support functions

function fatal {
    echo "$(basename $0): error: $1"
    exit 1
}

function errexit {
    [[ $1 -ne 0 ]] || exit 0
    fatal "error exit status $1 at line $2"
}

function ensure_manta_credentials {
    if [[ -z "$MANTA_KEY_ID" ]]; then
        export MANTA_KEY_ID=`ssh-keygen -l -f ~/.ssh/id_rsa.pub | awk '{print $2}' | tr -d '\n'`
    fi
    export MANTA_URL=https://us-east.manta.joyent.com
    if [[ -z "$MANTA_USER" ]]; then
        export MANTA_USER="Joyent_Dev";
    fi

    #
    # manta_base_path is used for preloading bits. So if we've been
    # passed in a -d option, we should use that here.
    #
    if [[ -z "$MG_DEP_USER" ]]; then
	MG_DEP_USER="$MANTA_USER"
    fi
    export manta_base_path="/$MG_DEP_USER/stor/builds"
}

# Blow away the bits cache once per-day because don't want it to grow
# unbounded in size (esp. for the continuous-build system). An alternative
# would be to put a size limit on it.
function flush_bits_cache() {
    if [[ -f $MG_CACHE_DIR/bits/created ]]; then
        local bits_cache_age=$((`date "+%s"` - `$MTIME $MG_CACHE_DIR/bits/created`))
        # One day in 86400. We use a bit more to avoid harmonics with
        # once-per-day builds.
        if [[ $bits_cache_age -gt 100000 ]]; then
            echo "# Bit cache '$MG_CACHE_DIR/bits' is more than a day old. Blowing it away to be recreated."
            rm -rf $MG_CACHE_DIR/bits
        fi
    fi
}

# areload $MG_CACHE_DIR/bits/ with the latest built and uploaded bits for
# the given target and branch via HTTP(S).
#
# Usage:
#   preload_bits_from_http TARGET BRANCH TRY_BRANCH
# where:
#   TARGET is a URL dir that serves Apache/Nginx-index-style directories.
#
# Example:
#   preload_bits_from_http http://download.joyent.com/pub/build/sdcnode master ""
#
function preload_bits_from_http() {
    local target=$1
    local branch=$2
    local try_branch=$3
    local target_base=$(basename $target)

    if [[ "$target_base" == "sdcnode" ]]; then
        echo "Skip preload of sdcnode (see RELENG-404)."
        return
    fi

    echo ""
    echo "# preload 'bits/$target_base'"

    local target_url
    [[ $(echo $target | cut -c 1-4) == "http" ]] || fatal "preload_bits_from_http called w/o http URL"

    target_url=$target
    if [[ "${target_url:(-1)}" != "/" ]]; then
        target_url=$target_url/
    fi
    local_cache_reldir=${target_url#*://}
    local_cache_reldir=${local_cache_reldir#*@}

    # Branch dir: try $try_branch, then $branch.
    local best_branch=$try_branch
    local latest_url=$target_url$try_branch-latest/
    if [[ -z "$best_branch" ||
          $($CURL -kI $latest_url | head -1 | awk '{print $2}') != "200" ]]; then
        best_branch=$branch
        latest_url=$target_url$branch-latest/
        if [[ $($CURL -kIS $latest_url | head -1 | awk '{print $2}') != "200" ]]; then
            fatal "'$target_url/$branch-latest/' does not exist"
        fi
    fi
    echo "# use branch '$best_branch'"

    # Find the latest build time for this branch.
    local latest_build=$($CURL -Sk $target_url \
        | grep "href=\"" \
        | cut -d'"' -f2 \
        | grep "^$best_branch-" \
        | grep -v -- '-latest/$' \
        | sort \
        | tail -1)
    local local_cache_dir=$MG_CACHE_DIR/bits/$local_cache_reldir$latest_build$target_base

    if [[ -d $local_cache_dir ]]; then
        echo "# local cache at '$local_cache_dir' already exists"
    else
        # Mark creation for bits cache flush every day.
        mkdir -p $MG_CACHE_DIR/bits
        if [[ ! -f $MG_CACHE_DIR/bits/created ]]; then
            touch $MG_CACHE_DIR/bits/created
        fi

        latest_url=$target_url$latest_build

        # Update cache in $MG_CACHE_DIR/bits
        # `-l 2`: Two levels deep needed for 2-level depth of 'agents' bits area.
        echo "# download from $latest_url"
        (cd $MG_CACHE_DIR/bits \
            && wget -q -np -l 2 --no-check-certificate -r -L -R 'index.html,*.log' \
                $latest_url$target_base/)
    fi
    local md5sums_path=$local_cache_dir/../md5sums.txt
    if [[ ! -f $md5sums_path ]]; then
        $CURL -Sk ${latest_url}md5sums.txt -o $md5sums_path
    fi

    # MD5 check of downloaded bits.
    for bit in $(cd $local_cache_dir/../ && find . -type f | grep -v md5sums.txt); do
        local correct_md5=$(grep $bit $md5sums_path | cut -d ' ' -f1)
        local actual_md5=$(openssl dgst -md5 < $local_cache_dir/../$bit | awk '{print $NF}')
        if [[ $correct_md5 != $actual_md5 ]]; then
            rm $local_cache_dir/../$bit
            fatal "md5 check failure on $local_cache_dir/../$bit (actual '$actual_md5', from md5sums '$correct_md5')"
        fi
    done

    # Copy over to bits dir.
    mkdir -p bits
    [[ -d "bits/$target_base" ]] && fatal "'bits/$target_base' already exists"
    $CP_LINK -PR $local_cache_dir bits/$target_base
}

#
# Preload $MG_CACHE_DIR/bits/ with the latest built and uploaded bits for
# the given target and branch.
#
# Usage:
#   preload_bits_from_manta TARGET BRANCH TRY_BRANCH
#
# Example:
#   preload_bits_from_manta smartlogin master ""
#   preload_bits_from_manta release-20110901-upgrade/agents-upgrade master ""
#
function preload_bits_from_manta() {
    local target=$1
    local branch=$2
    local try_branch=$3
    local target_base=$(basename $target)
    local start_time=$(date +%s)

    # Don't bork if this was already preloaded by another target.
    if [[ -d bits/$target_base ]]; then
        return;
    fi

    # This is a hack here for the case where we've got something like:
    #
    # https://download.joyent.com/pub/build/sdcnode
    #
    # in the 'deps'. We'll then use HTTP to download that bit.
    if [[ $(echo $target | cut -c 1-4) == "http" ]]; then
        preload_bits_from_http $@
        return 0
    fi

    echo ""
    echo "# preload 'bits/$target_base from Manta'"

    ensure_manta_credentials

    # You can specify "target" as branch/target, in which case we will use
    # the branch from there. If target does not have '/', dirname returns '.'
    local target_branch=$(dirname $target)
    if [[ "$target_branch" != "." ]]; then
        branch=$target_branch
    fi

    # Remember: target_base is something like 'agents-upgrade'
    local target_mpath=${manta_base_path}/${target_base}

    # Branch dir: try $try_branch, then $branch.
    local best_branch=$try_branch
    if [[ -z $best_branch ]]; then
        best_branch=$branch
    fi

    #
    # Each build dir has a "${branch}-latest" file, e.g.
    # "/Joyent_Dev/stor/builds/amon/master-latest" that contains the name
    # of the actual latest path. Something similar but with a "-<buildstamp>"
    # instead of "-latest" and we'll grab that into latest_dir.
    #
    local count=0
    local latest_dir=
    local delay=0
    local success=

    set +o errexit  # want to do our own error-handling here
    while [[ ${count} -lt ${MANTA_MAX_RETRIES} && -z ${success} ]]; do

        if [[ ${count} -gt 0 ]]; then
            cat /tmp/mget-output.$$
            delay=$((${count} * 20))
            if [[ $delay -gt 60 ]]; then
                delay=60
            fi
            echo "Could not get latest dir for target ${target}, retrying in ${delay}s"
            sleep ${delay}
        fi

        latest_dir=$(mget -v -q ${target_mpath}/${best_branch}-latest 2> /tmp/mget-output.$$)

        if [[ $? == 0 ]]; then
            success=1
        elif [[ "$branch" != "$best_branch" ]]; then
            # Try "branch" as a fallback, if we've specified "try_branch".
            latest_dir=$(mget -v -q ${target_mpath}/${branch}-latest)
            if [[ $? == 0 ]]; then
                success=1
            fi
        fi

        count=$((${count} + 1))
    done
    set -o errexit  # back to errexit

    if [[ -z ${latest_dir} ]]; then
        cat /tmp/mget-output.$$
        fatal "Could not get latest dir for target $target"
    fi

    # local_cache_dir will be something like:
    # /root/MG/cache/bits/agents-upgrade/master-20131213T003614Z
    local local_cache_dir=${MG_CACHE_DIR}/bits/${latest_dir#$manta_base_path/}
    mkdir -p ${local_cache_dir}

    # Mark creation for bits cache flush every day.
    if [[ ! -f $MG_CACHE_DIR/bits/created ]]; then
        touch $MG_CACHE_DIR/bits/created
    fi

    local cache_dirname=
    local cache_filename=
    local dir=
    local files=$(mfind -v -t o ${latest_dir})
    local found=
    local local_file_md5=
    local manta_file_md5=
    local retries=

    if [[ -z ${files} ]]; then
        fatal "failed to get files from ${latest_dir}"
    fi

    # loop through all the objects in the latest_dir
    for file in $files; do
        dir=$(dirname $file)
        cache_dirname=$(echo "${local_cache_dir}/${dir#${latest_dir}}" | sed -e "s/\/$//g" | sed -e "s|//|/|g")
        cache_filename=$(basename ${file})
        manta_file_md5=$(mmd5 -v ${file} | cut -d' ' -f1)

        # Ensure directory exists
        mkdir -p ${cache_dirname}

        retries=0
        while [[ ${retries} -lt ${MANTA_MAX_RETRIES} ]]; do
            if [[ ! -f ${cache_dirname}/${cache_filename} ]]; then
                mget -v ${MGET_BIT_ARGS} -o ${cache_dirname}/${cache_filename} ${file}
            fi

            local_file_md5=$(md5sum ${cache_dirname}/${cache_filename} | cut -d ' ' -f1)
            if [[ ${local_file_md5} == ${manta_file_md5} ]]; then
                echo "# ${cache_dirname}/${cache_filename} has correct MD5"
                break;
            else
                echo "# ${cache_dirname}/${cache_filename} has incorrect MD5, deleting"
                rm -f ${cache_dirname}/${cache_filename}
            fi
            retries=$((${retries} + 1))
        done

        [[ -f ${cache_dirname}/${cache_filename} ]] \
            || fatal "failed to preload ${cache_dirname}/${cache_filename}"
    done

    # Copy over to bits dir.
    mkdir -p bits
    [[ -d "bits/${target_base}" ]] && fatal "'bits/${target_base}' already exists"
    $CP_LINK -PR ${local_cache_dir}/${target_base} bits/${target_base}

    local end_time=$(date +%s)
    echo "$((${end_time} - ${start_time})) seconds to preload ${target_base}"
}

# Clone/update the given git repo in the repo cache.
# Usage:
#   get_repo_cache REPO-URL REPO-DIR SUBMODULE-UPDATE
# Example:
#   get_repo_cache git@git.joyent.com:smart-login.git smart-login true
function get_repo_cache() {
    local repo_url=$1
    local repo_dir=$2
    local dst_dir=$MG_CACHE_DIR/repos/$repo_dir

    if [[ ! -d "$MG_CACHE_DIR/repos/$repo_dir" ]]; then
        mkdir -p $MG_CACHE_DIR/repos
        local tmp_dir=$MG_CACHE_DIR/repos/.tmp.$repo_dir
        rm -rf $tmp_dir
        git clone $repo_url $tmp_dir
        mv $tmp_dir $MG_CACHE_DIR/repos/$repo_dir
    else
        (cd $MG_CACHE_DIR/repos/$repo_dir; git pull)
    fi
    if [[ "$submodule_update" == "true" ]]; then
        (cd $MG_CACHE_DIR/repos/$repo_dir; git submodule update --init --recursive)
    fi

    # Error out if the cached repo is dirty. These thigns should always
    # be pristine.
    if [[ "$(cd $MG_CACHE_DIR/repos/$repo_dir && git describe --all --dirty | grep dirty)" != "" ]]; then
        fatal "Repo '$repo_dir' cache, $MG_CACHE_DIR/repos/$repo_dir, is dirty!"
    fi
}


# Get the requested repo.
# Usage:
#   get_repo2 REPO-URL BRANCH SUBMODULE-UPDATE [NAME] [TRY-BRANCH]
#
# If "SUBMODULE-UPDATE" is "true", then "git submodule update ..." is
# used on the repo.
#
# If "NAME" is given, that subdir under "build/" will be used as the
# clone dir. Else it is inferred from the REPO-URL.
#
function get_repo2() {
    local repo_url=$1
    local branch=$2
    local submodule_update=$3
    local repo_dir=$4
    local try_branch=$5

    if [[ -z "$repo_dir" ]]; then
        repo_dir=${repo_url##*/}    # strip to last '/'
        repo_dir=${repo_dir##*:}    # strip to last ':'
        repo_dir=${repo_dir%*.git}    # strip '.git' at tail
    fi

    echo "# get '$repo_url' to repo cache ($MG_CACHE_DIR/repos)"
    get_repo_cache ${repo_url} ${repo_dir} ${submodule_update}

    echo "# copy '$MG_CACHE_DIR/repos/$repo_dir' to 'build/$repo_dir'"
    mkdir -p build
    cp -PR $MG_CACHE_DIR/repos/$repo_dir build/$repo_dir
    (cd build/$repo_dir ; git checkout $branch)

    if [[ ! -z "$try_branch" ]]; then
        (cd build/$repo_dir ; git checkout $try_branch && git pull || true)
    fi
    if [[ "$submodule_update" == "true" ]]; then
        (cd build/$repo_dir; git submodule update --init --recursive)
    fi
}

function gen_config() {
    local output
    mkdir -p bits
    cat <<EOF >bits/config.mk
TIMESTAMP=$(TZ=UTC date "+%Y%m%dT%H%M%SZ")
BRANCH=$BRANCH
TRY_BRANCH=$TRY_BRANCH
MG_NODE=$MG_NODE
MG_CACHE_DIR=$(cd $MG_CACHE_DIR >/dev/null; pwd)

EOF
  mkdir -p build
  for repo in $(ls -1 build/); do
      repo_mk_name=$(echo $repo | tr [:lower:] [:upper:] | tr - _)
      branch_name=$((cd build/${repo} && git symbolic-ref HEAD 2> /dev/null ) || echo "")
      echo ${repo_mk_name}_BRANCH=$(echo ${branch_name##refs/heads/} || echo "") >> ${ROOT}/bits/config.mk
      echo ${repo_mk_name}_SHA=$((cd build/${repo} && git log --pretty=format:'%h' -1 ) || echo "") >> ${ROOT}/bits/config.mk
  done

  # Makefile vars for appliance builds (i.e. the "foo_image" targets).
  for targ in $TARGETS; do
      targ_mk_name=$(echo $targ | tr [:lower:] [:upper:] | tr - _)
      if [[ $(cat ${ROOT}/targets.json | $JSON ${targ} | $JSON appliance) == 'true' ]]; then
        echo ${targ_mk_name}_IMAGE_UUID=$(cat ${ROOT}/targets.json | $JSON ${targ}.image_uuid) >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_IMAGE_NAME=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.image_name)\" >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_IMAGE_DESCRIPTION=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.image_description)\" >> ${ROOT}/bits/config.mk
        echo ${targ_mk_name}_PKGSRC=\"$(cat ${ROOT}/targets.json | $JSON ${targ}.pkgsrc | $JSON -a |  xargs)\" >> ${ROOT}/bits/config.mk
        local num_tarballs=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.length)
        local tarballs=""
        local index=0
        while [[ ${index} -lt ${num_tarballs} ]]; do
            local tb_name=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.name)
            local tb_tarball=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.tarball)
            [[ -z "$tb_tarball" ]] && fatal "no '$targ.tarballs.$index.tarball' in targets.json"
            tb_tarball=$ROOT/bits/$tb_tarball
            local tb_sysroot=$(cat ${ROOT}/targets.json | $JSON ${targ}.tarballs.${index}.sysroot)
            [[ -z "$tb_sysroot" ]] && fatal "no '$targ.tarballs.$index.sysroot' in targets.json"
            tarballs="$tarballs $tb_tarball:$tb_sysroot"
            index=$((${index} + 1))
        done
        echo ${targ_mk_name}_EXTRA_TARBALLS=\"${tarballs}\" >> ${ROOT}/bits/config.mk
      fi
  done
}


function print_help() {
    echo "Configure this SDC build. This involves cloning/pulling the "
    echo "component source repositories."
    echo ""
    echo "Usage:"
    echo "  ./configure [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -h, --help   Print this help and exit."
    echo ""
    echo "  -n NODE_EXE  Path to node exe for MG to use."
    echo ""
    echo "  -b BRANCH    Branch to checkout. Defaults to 'master'."
    echo "               Note that this is for *all* core repositories."
    echo "  -B TRY-BRANCH"
    echo "               Branch to try to checkout (if it exists). '-b' value"
    echo "               is used as the default. This is useful for building"
    echo "               a feature branch on one of the many repos used for"
    echo "               a target."
    echo "  -t TARGET    Prepare to build only this target. Valid targets are"
    echo "               the keys of 'targets.json' plus a special value"
    echo "               'all-except-platform' to build all targets except the"
    echo "               slow-to-build platform."
    echo "  -r           Regenerate config.mk. This doesn't touch repos in"
    echo "               'build/' or preload in 'bits/'."
    echo "  -c CACHE-DIR Specify a cache directory. Default: './cache'."
    echo "               The cache is used for caching git clones, preloaded"
    echo "               bits and npm downloads. The 'bits cache' is"
    echo "               automatically removed if it is more than a day old."
    echo "  -d USER      Alternate user to pull dependencies from. eg. if "
    echo "               building as yourself, -d Joyent_Dev will pull deps "
    echo "               from normal builds."
    exit 0
}


function get_target_repos() {
    local target=$1
    local info
    for info in `cat targets.json | $JSON $target.repos | $JSON -a -d, url dir submodule-update`; do
        local repo_url=$(echo "$info" | cut -d, -f 1)
        local repo_dir=$(echo "$info" | cut -d, -f 2)
        local submodule_update=$(echo "$info" | cut -d, -f 3)
        [[ -z "$submodule_update" ]] && submodule_update=true
        get_repo2 $repo_url $BRANCH "$submodule_update" "$repo_dir" "$TRY_BRANCH"
    done
}

function get_pkgsrc() {
  if [[ -d ${ROOT}/build/usb-headnode ]]; then
    echo "# get pkgsrc packages for build/usb-headnode zones (to build/pkgsrc)"

    mkdir -p build/pkgsrc/

    set -o xtrace

    shopt -s extglob

    for dataset in $(find ${ROOT}/build/usb-headnode/zones -name "dataset"); do
      local ds=$(cat ${dataset})
      local pkgsrc_url=$((${JSON} datasets | ${JSON} -a name pkgsrc_url \
          | grep "$(basename ${ds%\.dsmanifest})" \
          | cut -d ' ' -f2) < ${ROOT}/build/usb-headnode/build.spec)
      if [[ ${pkgsrc_url:(-1)} != "/" ]]; then
        pkgsrc_url=$pkgsrc_url/
      fi
      local pkgsrc_ver=$(echo "${pkgsrc_url}" | cut -d '/' -f5)
      local gccver=$(echo "${pkgsrc_url}" | cut -d '/' -f6)

      local cache_dir=$MG_CACHE_DIR/pkgsrc/$pkgsrc_ver/$gccver/All
      local dest_dir=build/pkgsrc/${pkgsrc_ver}/${gccver}/All
      mkdir -p $cache_dir
      mkdir -p $dest_dir

      if [[ ! -f $dest_dir/../SHA512.bz2 ]]; then
        echo "# get ${pkgsrc_url}/../SHA512.bz2"
        if ${CURL} -S -o $cache_dir/../SHA512.bz2 ${pkgsrc_url}/../SHA512.bz2; then
          $CP_LINK $cache_dir/../SHA512.bz2 $dest_dir/../SHA512.bz2
        elif [[ ! -f $dest_dir/md5sums.txt ]]; then
          echo "# get ${pkgsrc_url}md5sums.txt"
          ${CURL} -S -o $cache_dir/md5sums.txt ${pkgsrc_url}md5sums.txt
          $CP_LINK $cache_dir/md5sums.txt $dest_dir/md5sums.txt
        fi
      fi

      for file in $(cat $(dirname ${dataset})/pkgsrc); do
        if [[ -f $dest_dir/$file.tgz ]]; then
          true # pass through
        else
          if [[ ! -f $cache_dir/${file}.tgz ]]; then
            echo "# get ${pkgsrc_url}${file}.tgz"
            ${CURL} -S -o $cache_dir/$file.tgz ${pkgsrc_url}/${file}.tgz

            if [[ -f $cache_dir/../SHA512.bz2 ]]; then
              local correct_sha512=$(bzcat ${cache_dir}/../SHA512.bz2 | grep "/${file}.tgz)" | cut -d' ' -f4)
              local actual_sha512=$(openssl dgst -sha512 < $cache_dir/$file.tgz | awk '{print $NF}')
              if [[ $correct_sha512 != $actual_sha512 ]]; then
                rm $cache_dir/$file.tgz
                fatal "SHA512 check failure on $cache_dir/$file.tgz (actual $actual_sha512, from SHA512.bz2 $correct_sha512)"
              fi
            elif [[ -f $cache_dir/md5sums.txt ]]; then
              local correct_md5=$(grep $file $cache_dir/md5sums.txt | cut -d ' ' -f1)
              local actual_md5=$(openssl dgst -md5 < $cache_dir/$file.tgz | awk '{print $NF}')
              if [[ $correct_md5 != $actual_md5 ]]; then
                rm $cache_dir/$file.tgz
                fatal "md5 check failure on $cache_dir/$file.tgz (actual $actual_md5, from md5sums $correct_md5)"
              fi
            fi
          else
            echo "# have $cache_dir/$file.tgz"
          fi
          $CP_LINK $cache_dir/$file.tgz $dest_dir/
        fi
      done
    done

    set +o xtrace

  fi
}




#---- mainline

trap 'errexit $? $LINENO' EXIT

# Can be a target name to tell 'configure' to (a) limit prep to just that
# target and (b) pre-load "bits/" with pre-built dependent target bits.
# If empty it means that we are configuring for a full build.
TARGET=
REGENERATE='false'
MG_NODE=$(which node)


if [[ "$1" == "--help" ]]; then
  print_help
fi
while getopts "b:B:d:hrft:c:" opt; do
    case "$opt" in
        b) BRANCH=$OPTARG ;;
        B) TRY_BRANCH=$OPTARG ;;
        h) print_help ;;
        r)
            REGENERATE='true'
            ;;
        t) TARGET=${OPTARG} ;;
        c) MG_CACHE_DIR=${OPTARG} ;;
        d) MG_DEP_USER=${OPTARG} ;;
        ?) fatal "unknown option: $opt" ;;
    esac
done
shift $((OPTIND-1))


# Pre-condition: must have node >=0.10 first on path (see RELENG-266).
echo "Ensure have a 'node' >= v0.10."
NODE_VERSION=$($MG_NODE --version | awk 'BEGIN{ FS="." } { print $2 }')
if [[ $NODE_VERSION -lt 10 ]]; then
    fatal "Incorrect node version, '${NODE_VERSION}'. MG needs a node v0.10 or later on your PATH."
fi
JSON="$MG_NODE $ROOT/tools/json"

# make sure we clean out old versions before installing the new one
for nodething in manta smartdc; do
    if [[ -f node_modules/${nodething}/package.json
         && $(json version < node_modules/${nodething}/package.json) \
         != $(json dependencies.${nodething} < package.json) ]]; then

        rm -rf node_modules/${nodething}
    fi
done

# Make sure npm stuff is installed
npm install

# '-r' regenerate early out.
if [[ "$REGENERATE" == 'true' ]]; then
    gen_config
    exit 0
fi


# Else we are doing a full configure for a fresh build. Start fresh:
mkdir -p bits
touch bits/config.mk
make distclean

if [[ ! -z "$TARGET" ]]; then
    flush_bits_cache
    if [[ "$TARGET" == "all-except-platform" ]]; then
        preload_bits_from_manta "platform" "$BRANCH" "$TRY_BRANCH"
        TARGETS=$(${MG_NODE} -e 'fs=require("fs"); c=fs.readFileSync("targets.json"); console.log(Object.keys(JSON.parse(c)).join("\n"))' | grep -v '^platform')
        for targ in $TARGETS; do
            get_target_repos $targ
            for dep in `cat targets.json | $JSON $targ.deps | $JSON -a`; do
                if [[ -n "$(echo $dep | grep / | grep -v 'https*:'  || true)" ]]; then
                    # Using the 'BRANCH/NAME' form to lock to a branch.
                    dep_branch=$(echo $dep | cut -d/ -f1)
                    dep=$(echo $dep | cut -d/ -f2)
                    preload_bits_from_manta ${dep} "${dep_branch}"
                else
                    preload_bits_from_manta ${dep} "$BRANCH" "$TRY_BRANCH"
                fi
                dep_branch
            done
        done
    else
        # Validate target.
        TARGETS=$TARGET
        if [[ -z "$(cat targets.json | $JSON $TARGET)" ]]; then
            fatal "Unknown target: $TARGET"
        fi
        get_target_repos $TARGET
        for dep in `cat targets.json | $JSON $TARGET.deps | $JSON -a`; do
            if [[ -n "$(echo $dep | grep /  | grep -v 'https*:' || true)" ]]; then
                # Using the 'BRANCH/NAME' form to lock to a branch.
                dep_branch=$(echo $dep | cut -d/ -f1)
                dep=$(echo $dep | cut -d/ -f2)
                preload_bits_from_manta ${dep} "${dep_branch}"
            else
                preload_bits_from_manta ${dep} "$BRANCH" "$TRY_BRANCH"
            fi
        done
    fi
else
    TARGETS=$(${MG_NODE} -e 'fs=require("fs"); c=fs.readFileSync("targets.json"); console.log(Object.keys(JSON.parse(c)).join("\n"))')
    for targ in $TARGETS; do
        get_target_repos $targ
    done
fi

# "all" is a special target with deps to always preload.
# I.e. for which "make all" doesn't build it.
for dep in `cat targets.json | $JSON all.deps | $JSON -a`; do
    if [[ -n "$(echo $dep | grep / || true)" ]]; then
        # Using the 'BRANCH/NAME' form to lock to a branch.
        dep_branch=$(echo $dep | cut -d/ -f1)
        dep=$(echo $dep | cut -d/ -f2)
        preload_bits_from_manta ${dep} "${dep_branch}"
    else
        preload_bits_from_manta ${dep} "$BRANCH" "$TRY_BRANCH"
    fi
done

#get_pkgsrc

gen_config
